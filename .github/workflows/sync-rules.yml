name: 1. Daily Sync and Sanitize Rules (mihomo-core, robust)

on:
  workflow_dispatch:
  schedule:
    - cron: '0 21 * * *'  # 北京时间 05:00

permissions:
  contents: write

concurrency:
  group: sync-rules
  cancel-in-progress: true

jobs:
  sync-job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Build sanitized URL list
        id: build_urls
        run: |
          set -euo pipefail
          if [ ! -f sources.urls ]; then
            echo "sources.urls not found, skip."
            exit 0
          fi
          TMP_DIR="${RUNNER_TEMP}/sync-tmp"
          mkdir -p "$TMP_DIR"
          URLS="${TMP_DIR}/urls.cleaned"
          : > "$URLS"

          # 逐行净化 sources.urls：
          # - 去 BOM（首行）
          # - 去 CR（Windows 行尾）
          # - 去首尾空格
          # - 去行尾注释：空格后跟 # 及其后续内容
          # - 过滤空行和以 # 开头的纯注释行
          awk 'NR==1{ sub(/^\xEF\xBB\xBF/,"") } { print }' sources.urls \
          | sed 's/\r$//' \
          | sed -E 's/[[:space:]]+#.*$//' \
          | sed -E 's/^[[:space:]]+//; s/[[:space:]]+$//' \
          | grep -v -E '^#|^$' \
          > "$URLS"

          echo "sanitized_urls_file=$URLS" >> $GITHUB_OUTPUT

      - name: Sync, Prune, and Sanitize Rule Files
        if: steps.build_urls.outputs.sanitized_urls_file != ''
        run: |
          set -euo pipefail
          SOURCE_DIR="rulesets"
          URLS_FILE="${{ steps.build_urls.outputs.sanitized_urls_file }}"
          TMP_DIR="${RUNNER_TEMP}/sync-tmp"
          mkdir -p "$TMP_DIR"

          get_owner_dir() {
            local url="$1"
            local host=$(echo "$url" | awk -F/ '{print $3}')
            if [ "$host" = "raw.githubusercontent.com" ]; then
              echo "$url" | awk -F/ '{print $4}'
            elif [ "$host" = "cdn.jsdelivr.net" ]; then
              # https://cdn.jsdelivr.net/gh/<owner>/<repo>@<ref>/...
              local p4=$(echo "$url" | awk -F/ '{print $4}')
              if [ "$p4" = "gh" ]; then
                echo "$url" | awk -F/ '{print $5}'
              else
                echo "$host"
              fi
            else
              echo "$host"
            fi
          }

          EXP="${TMP_DIR}/expected_files.list"
          ACT="${TMP_DIR}/actual_files.list"
          : > "$EXP"
          : > "$ACT"

          # 构建期望文件列表（基于“已净化”的 URL 列表）
          while IFS= read -r url; do
            owner="$(get_owner_dir "$url")"
            fn="$(basename "$url")"
            echo "${SOURCE_DIR}/${owner}/${fn}" >> "$EXP"
          done < "$URLS_FILE"

          # 实际文件
          if [ -d "$SOURCE_DIR" ]; then
            find "$SOURCE_DIR" -type f > "$ACT"
          fi

          sort -u "$ACT" -o "$ACT" || true
          sort -u "$EXP" -o "$EXP"

          # 删除不再需要的文件
          comm -23 "$ACT" "$EXP" | while read -r f; do
            [ -n "$f" ] && echo "Prune: $f" && rm -f "$f" || true
          done

          # 拉取并净化规则内容
          while IFS= read -r url; do
            owner="$(get_owner_dir "$url")"
            fn="$(basename "$url")"
            out="${SOURCE_DIR}/${owner}/${fn}"

            echo "Fetch -> ${url}"
            # 记录 HTTP 状态码，失败则跳过
            code=$(curl -sL --create-dirs -o "${out}.download" -w "%{http_code}" "$url" || true)
            if [ "$code" -lt 200 ] || [ "$code" -ge 300 ]; then
              echo "Warn: HTTP $code for $url. Skip."
              rm -f "${out}.download"
              continue
            fi

            # 内容净化（适配 mihomo-core）：
            # - 去 BOM, 去 CRLF
            # - 若首行是 payload: 则删除
            # - 去注释行(#/! 开头)与空行
            # - trim 首尾空白、规范逗号两侧空格
            # - 保留原格式（裸域名或已带类型行）
            awk 'NR==1{ sub(/^\xEF\xBB\xBF/,"") } { print }' "${out}.download" \
            | sed 's/\r$//' \
            | sed '1{/^[[:space:]]*payload:[[:space:]]*$/d;}' \
            | grep -v -E '^[[:space:]]*#|^[[:space:]]*!' \
            | sed '/^[[:space:]]*$/d' \
            | sed -E 's/^[[:space:]]+//; s/[[:space:]]+$//; s/[[:space:]]*,[[:space:]]*/,/g' \
            > "$out"

            rm -f "${out}.download"
            echo "Saved: $out"
          done < "$URLS_FILE"

          # 清空空目录
          [ -d "$SOURCE_DIR" ] && find "$SOURCE_DIR" -type d -empty -delete || true

      - name: Commit Changes (only if any)
        run: |
          if [[ -z $(git status -s) ]]; then
            echo "No changes."
            exit 0
          fi
          git config user.name 'GitHub Actions Bot'
          git config user.email 'actions@github.com'
          git add -A
          git commit -m "chore(daily-sync): Update rule sets for $(date +'%Y-%m-%d')"
          git push
