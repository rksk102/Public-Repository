name: 1. Daily Sync and Sanitize Rules (mihomo-core, enhanced)

on:
  workflow_dispatch:
  schedule:
    - cron: '0 21 * * *'  # 北京时间 05:00

permissions:
  contents: write

concurrency:
  group: sync-rules
  cancel-in-progress: true

jobs:
  sync-job:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4

      # 预清洗 sources.urls，去 BOM/CR/尾注释/空行
      - name: Build sanitized URL list
        id: build_urls
        run: |
          set -euo pipefail
          if [ ! -f sources.urls ]; then
            echo "sources.urls not found, skip."
            exit 0
          fi
          TMP_DIR="${RUNNER_TEMP}/sync-tmp"
          mkdir -p "$TMP_DIR"
          URLS="${TMP_DIR}/urls.cleaned"
          : > "$URLS"

          awk 'NR==1{ sub(/^\xEF\xBB\xBF/,"") } { print }' sources.urls \
          | sed 's/\r$//' \
          | sed -E 's/[[:space:]]+#.*$//' \
          | sed -E 's/^[[:space:]]+//; s/[[:space:]]+$//' \
          | grep -v -E '^#|^$' \
          > "$URLS"

          echo "sanitized_urls_file=$URLS" >> $GITHUB_OUTPUT

      - name: Sync, Prune, and Sanitize Rule Files
        if: steps.build_urls.outputs.sanitized_urls_file != ''
        run: |
          set -euo pipefail
          SOURCE_DIR="rulesets"
          URLS_FILE="${{ steps.build_urls.outputs.sanitized_urls_file }}"
          TMP_DIR="${RUNNER_TEMP}/sync-tmp"
          mkdir -p "$TMP_DIR"

          # 可选严格模式（有失败则 fail）
          STRICT="${STRICT:-false}"
          fail_count=0

          get_owner_dir() {
            local url="$1"
            local host=$(echo "$url" | awk -F/ '{print $3}')
            if [ "$host" = "raw.githubusercontent.com" ]; then
              echo "$url" | awk -F/ '{print $4}'
            elif [ "$host" = "cdn.jsdelivr.net" ]; then
              # https://cdn.jsdelivr.net/gh/<owner>/<repo>@<ref>/...
              local p4=$(echo "$url" | awk -F/ '{print $4}')
              if [ "$p4" = "gh" ]; then
                echo "$url" | awk -F/ '{print $5}'
              else
                echo "$host"
              fi
            else
              echo "$host"
            fi
          }

          try_download() {
            local url="$1"; local out="$2"
            local code
            # 第一次下载
            code=$(curl -sL --create-dirs -o "${out}.download" -w "%{http_code}" "$url" || true)
            if [ "$code" -ge 200 ] && [ "$code" -lt 300 ]; then
              echo "OK  ($code): $url"
              echo "$url" > "${out}.source"
              return 0
            fi
            echo "Warn ($code): $url"

            # 已知纠错：Loyalsoldier/clash-rules 的 /release/ruleset/ -> /release/
            if [[ "$url" == https://raw.githubusercontent.com/Loyalsoldier/clash-rules/release/ruleset/* ]]; then
              local alt="${url/\/release\/ruleset\//\/release\/}"
              echo "Retry with corrected URL: $alt"
              code=$(curl -sL -o "${out}.download" -w "%{http_code}" "$alt" || true)
              if [ "$code" -ge 200 ] && [ "$code" -lt 300 ]; then
                echo "OK  ($code): $alt"
                echo "$alt" > "${out}.source"
                return 0
              else
                echo "Fail($code): $alt"
              fi
            fi

            rm -f "${out}.download"
            return 1
          }

          # 构建期望文件列表（基于净化后的 URL）
          EXP="${TMP_DIR}/expected_files.list"
          ACT="${TMP_DIR}/actual_files.list"
          : > "$EXP"; : > "$ACT"

          while IFS= read -r url; do
            owner="$(get_owner_dir "$url")"
            fn="$(basename "$url")"
            echo "${SOURCE_DIR}/${owner}/${fn}" >> "$EXP"
          done < "$URLS_FILE"

          if [ -d "$SOURCE_DIR" ]; then
            find "$SOURCE_DIR" -type f > "$ACT"
          fi

          sort -u "$ACT" -o "$ACT" || true
          sort -u "$EXP" -o "$EXP"

          # 删除“孤儿”文件
          comm -23 "$ACT" "$EXP" | while read -r f; do
            [ -n "$f" ] && echo "Prune: $f" && rm -f "$f" || true
          done

          # 拉取并净化
          while IFS= read -r url; do
            owner="$(get_owner_dir "$url")"
            fn="$(basename "$url")"
            out="${SOURCE_DIR}/${owner}/${fn}"

            echo "Fetch -> ${url}"
            if ! try_download "$url" "$out"; then
              echo "::warning::Download failed for $url"
              fail_count=$((fail_count+1))
              continue
            fi

            # 增强版净化器（适配 mihomo-core 的纯文本规则）
            # - 去 BOM、去 CRLF
            # - 若首行是 payload: 删除
            # - 去整行注释与行尾内联注释
            # - YAML 列表项转纯文本（去掉 "- " 前缀与包裹引号）
            # - 去中文逗号后的说明
            # - Trim 与规范逗号空格
            # - 保留裸域名/原规则行
            awk 'NR==1{ sub(/^\xEF\xBB\xBF/,"") } { print }' "${out}.download" \
            | sed 's/\r$//' \
            | sed '1{/^[[:space:]]*payload:[[:space:]]*$/d;}' \
            | grep -v -E '^[[:space:]]*#|^[[:space:]]*!' \
            | sed -E 's/[[:space:]]+#.*$//' \
            | sed '/
            
